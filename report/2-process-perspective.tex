\section{Process's perspective} \label{section:Process perspective}
\todo{Also reflect and describe what was the "DevOps" style of your work. For example, what did you do differently to previous development projects and how did it work?}

\subsection{Interactions and organization of developer team} %jesper
The developer team stay in contact through a Microsoft Teams team, where we have regular meetings every Monday and usually one or two additional "stand up" type meetings to check in on progress throughout the week. The Teams chat is also used for some links and logins, as well as communication regarding individual tasks. \\ \indent Major issues are typically done with everyone present if they require important decisions, otherwise, work is usually done individually or in groups or two or three people - depending on the complexity of the task ahead.
 

\subsection{CI/CD chain} %jesper
For CI, we initially attempted to use TravisCI, as everyone in the group had encountered it. We ended up abandoning TravisCI due to an overwhelming number of issues with files and folders not being added properly, in addition to not being able to make proper use of necessary secrets. \\ \indent We instead settled for using GitHub Actions, which had all the features we wanted (triggers, stages, customizable images and non-local storage of secrets).

\begin{itemize}
    \item \textbf{Java CI with Maven}: This is invoked on all pushes to the github repository. It builds the maven project using $mvn package$ and runs all tests, including integration tests on a remote test database. This workflow utilizes caching to ensure that maven dependencies aren't fetched on consecutive runs. 
    \item \textbf{Staging deployment}: This is invoked on all pushes to the main branch. This workflow logs into DockerHub, builds and pushes the minitwit docker image with database secrets. Afterwards it SSH's to the primary minitwit server and fetches the minitwit config files, including the docker-compose file. Immediately after all containers are torn down and rebuild using the newly pushed minitwit image from DockerHub. Finally, a release is created with new commits linked and the backup server is redeployed similarly. In the downtime of the primary server the backup server obtains the floating IP and vice versa. 
    \item \textbf{Backup DB}: Once a day Github action SSH into the primary server and creates a database dump with time and date in the name. Created to minimize potential data loss. 
    \item \textbf{Build LaTeX document}: When a push to develop occurs, the LaTeX files are fetched and a pdf document will be built when changes are pushed to the report directory in the repository\todo{isn't this contradicting?}. The LaTeX files are manually fetched from a remote Overleaf repository, as Overleaf facilitates the groups collaborative writing. 
    \item \textbf{SonarCloud}: Official SonarCloud github action that builds and analyzes the java project using \textit{mvn\_verify}. 
\end{itemize}
\todo{describe secret handling}


\subsection{Organization of repository}
The code is organized using a mono repository setup, having all code and scripts necessary to run the application gathered in a single repository. The team deemed this sufficient as everything located in the repository (apart from local dockerfiles and simulator) is involved in the deployment process and the code-base is small and simple enough that having multiple repositories would only increase complexity. 

%, \underline{\href{https://github.com/DevOps2021-gb/devops2021}{devops2021}.}

\subsection{Applied branching strategy and development process} %frederik
The group decided on using the master branch for the latest release meaning that the code found in production, could also be found on the master branch. The develop branch facilitated the main development of the project which should always contain a working build. From develop each group member could create feature branches (\texttt{feature/logging} for example) and then merge back into develop once tested and approved. Develop could be subject to hotfixes, which would then be merged into master when issues arose. The full process can be seen in \underline{\href{https://github.com/DevOps2021-gb/devops2021/blob/main/CONTRIBUTE.md}{CONTRIBUTE.md}}. The group used GitHub issues to track development progress labeling them as needed with tags such as bug, documentation, feature, enhancement and so on. The status of each issue and the issues to focus on each week was tracked using GitHub's kanban board, having columns 'Todo', 'This sprint', 'In progress' and 'Done'.

\subsection{Monitoring} %Jonas
Monitoring is set up using Prometheus and Grafana, where Prometheus is used to subtract data from the system, at the data is displayed on dashboards in Grafana.\\
The newest data points displayed collected by Prometheus are collected and stored using \texttt{MaintenanceService.java}. Each data type is stored in prometheus library's Gauge or Counter objects, which is registered with a unique name and help description. Data gathered is the current cpu load, data base information and response-time of each endpoint. The data is collected with an interval of 30s by it calling the "/metrics" endpoint. The configuration of Prometheus can be seen in file \texttt{prometheus.yml} \footnote{\url{https://github.com/DevOps2021-gb/devops2021/blob/main/prometheus.yml}}.

On \textit{Grafana} three dashboards were created:
\begin{itemize}
    \item \textbf{Minitwit DB info} shows information about the data stored in the database, e.g. the current number of users registered for the application \footnote{\url{http://144.126.244.138:3000/dashboard/db/minitwit-db-info?orgId=1}}.
    \begin{figure}[H]
        \centering
        \includegraphics[width=1.0\textwidth]{images/Grafana_minitwit_db.JPG}
        \caption{Grafana dashboard minitwit db}
        \label{fig:grafana_db}
    \end{figure}
    
    \item \textbf{Minitwit request}\footnote{\url{http://144.126.244.138:3000/dashboard/db/minitwit-requests?orgId=1}} shows response times for requests to the system.
    \begin{figure}[H]
        \centering
        \includegraphics[width=1.0\textwidth]{images/Grafana_minitwit_requests.JPG}
        \caption{Grafana dashboard minitwit requests}
        \label{fig:grafana_requests}
    \end{figure}
    
    \item \textbf{Prometheus Stats}\footnote{\url{http://144.126.244.138:3000/dashboard/db/prometheus-stats?orgId=1}} shows the uptime of the system. The time is reset when the system is redeployed or if it goes down.
    \begin{figure}[H]
        \centering
        \includegraphics[width=1.0\textwidth]{images/Grafana_prometheous_stats.JPG}
        \caption{Grafana dashboard Prometheus Stats}
        \label{fig:grafana_prometheus}
    \end{figure}
\end{itemize}
The graphs in the dashboards show min, max and average of the platted data and those with a heart in the title contains alerts that every 60 seconds check if latest value is below certain values which indicates that a critical error has occurred. When/if such an alert is triggered Grafana should be setup to email the members of the team.



\subsection{Logging}
Logging is set up as an EFK stack. Initially only exceptions were logged but during the logging exercise we found only one of the three introduced bugs could by detected by our logging system, telling us our logging was insufficient. Afterwards more detailed logging was introduced now also logging requests and their payloads with the exception of passwords which was removed. This change made all three kinds of bug show up in the log. The description of the experiment can be found in the wiki entry \underline{\href{https://github.com/DevOps2021-gb/devops2021/wiki/Catch-a-Bug-By-Looking-at-the-Logs}{Catch a Bug By Looking at the Logs}}. Logging is done using Java's Logger object and though our helper-functions each print is extended with a classification/level. The prints also gets an code to easier filter only actual warnings instead of also messages containing the word warning. The class printing is also added to the message to easily track down which class caused that message.\\
These measures allowed us to create filters for Grafana dashboards such that we could see all messages, all warnings and all of the different kinds of exceptions that could be thrown. 
\todo{log volumes, traces, exceptions}


\subsection{Security assessment} %Jonas %self and from group a/L
In order to assess the security of the system two tasks were undertaken. A risk assessment was conducted and a penetration testing was performed.\\
For the rick assessment three assets to protect was identified: the web application, the database and the logging. The following potential threats were assessed:
\begin{itemize}
    \item Web application: SQL injection, cross site scripting, Dos, brute forcing login and insufficient logging and monitoring.
    \item Database: SQL injection through web application/API and lost authentication secrets.
    \item Logging: Dos attacks, brute forcing login page.
\end{itemize}

A risk analysis table was constructed and 11 scenarios7issues were identified and graded. For most of the scenarios actions had already been taken to prevent or mitigate the risks. For a few other scenarios possible actions were identified but not taken as they were not deemed necessary. The full details of the risks assessment can be found under \underline{\href{https://github.com/DevOps2021-gb/devops2021/wiki/Risk-assesment}{Risk Assessment}}.\\

For the penetration testing three tools were used: \textit{nmap}, \textit{metasploit} and \textit{SQL map}.In each case no vulnerabilities were found. In addition to using \textit{SQL map} cross-site scripting was also tested manually in multiple browsers by trying to use script-tags in the message input field on the website. In all tested browsers the script tag was not rendered. Lastly, it was checked that traces of the tools run showed up in the logging. The full details of the penetration test can be seen in \underline{\href{https://github.com/DevOps2021-gb/devops2021/wiki/Penetration-testing}{Penetration testing}}. \\

Another group was supposed to perform a white hat attack on the system. Nothing was heard from the group and it must be assumed that they found nothing to report or tested another group by mistake, as there were some confusion regarding targets.

\subsection{Scaling and load balancing}\label{subsection:scaling} %Nikolaj/Frederik
The group first implemented the traditional Heartbeat with Floating IPs on DigitalOcean \footnote{\url{https://www.digitalocean.com/community/tutorials/how-to-create-a-high-availability-setup-with-heartbeat-and-floating-ips-on-ubuntu-16-04}}. Unfortunately this would only ensure that floating IP were switched to the backup and back when the entire machine would go down. We did not find a configuration of Heartbeat that would allow us to listen on a specific port, and switch floating IP's when the minitwit service was down. We therefore decided to write two shell script to gain the sought after functionality. The first script\todo{found in: ???} continuously running on the secondary droplet checking the availability of the primary droplet, reassigning the floating-ip to itself should the application on the primary droplet go down. The second script would run on the primary droplet to reassign the floating-ip to itself when it restarted \footnote{\url{https://github.com/DevOps2021-gb/devops2021/tree/main/heartbeat}}